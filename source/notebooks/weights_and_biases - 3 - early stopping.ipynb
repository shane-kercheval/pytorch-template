{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "from source.domain.pytorch_wrappers import EarlyStopping\n",
    "\n",
    "# save weights and biases api key to .env file in project directory\n",
    "assert os.getenv('WANDB_API_KEY')\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)  # noqa: NPY002\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.config.fileConfig(\n",
    "    os.path.join(os.getcwd(), '/code/source/config/logging.conf'),\n",
    "    # defaults={'logfilename': os.path.join(os.getcwd(), 'tests/test_files/log.log')},\n",
    "    disable_existing_loggers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 20:03:56 - ERROR    | Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshane-kercheval\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 20:04:01 - INFO     | Training set  : X-torch.Size([56000, 1, 28, 28]), y-torch.Size([56000])\n",
      "2023-12-29 20:04:01 - INFO     | Validation set: X-torch.Size([7000, 1, 28, 28]), y-torch.Size([7000])\n",
      "2023-12-29 20:04:01 - INFO     | Test set      : X-torch.Size([7000, 1, 28, 28]), y-torch.Size([7000])\n"
     ]
    }
   ],
   "source": [
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True, parser='auto')\n",
    "x = torch.tensor(x.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.astype(int).values, dtype=torch.long)\n",
    "\n",
    "# need to make this dynamic based on Fully Connected vs Convolutional\n",
    "# Reshape data to have channel dimension\n",
    "# MNIST images are 28x28, so we reshape them to [batch_size, 1, 28, 28]\n",
    "x = x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "# 80% train; 10% validation; 10% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "logging.info(f\"Training set  : X-{x_train.shape}, y-{y_train.shape}\")\n",
    "logging.info(f\"Validation set: X-{x_val.shape}, y-{y_val.shape}\")\n",
    "logging.info(f\"Test set      : X-{x_test.shape}, y-{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \"\"\"Convolutional neural network (two convolutional layers).\"\"\"\n",
    "\n",
    "    def __init__(self, kernels: list, classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(x: torch.tensor, y: torch.tensor, batch_size: int) -> DataLoader:\n",
    "    \"\"\"Make a DataLoader from a given dataset.\"\"\"\n",
    "    return DataLoader(\n",
    "        dataset=TensorDataset(x, y),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "\n",
    "def make(config: dict) -> tuple:\n",
    "    \"\"\"Make the model, data, and optimization objects.\"\"\"\n",
    "    # Make the data\n",
    "    train_loader = make_loader(x_train, y_train, batch_size=config.batch_size)\n",
    "    validation_loader = make_loader(x_val, y_val, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(x_test, y_test, batch_size=config.batch_size)\n",
    "\n",
    "    # Make the model\n",
    "    model = ConvNet(config.kernels, config.classes).to(DEVICE)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == 'Adam':\n",
    "        optimizer_creator = lambda lr: torch.optim.Adam(model.parameters(), lr=lr)  # noqa: E731\n",
    "    elif config.optimizer == 'SGD':\n",
    "        optimizer_creator = lambda lr: torch.optim.SGD(model.parameters(), lr=lr)  # noqa: E731\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {config.optimizer}\")\n",
    "\n",
    "    learning_rates = config.learning_rates\n",
    "    if isinstance(learning_rates, float):\n",
    "        learning_rates = [learning_rates]\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        train_loader,\n",
    "        validation_loader,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        optimizer_creator,\n",
    "        learning_rates,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_log(\n",
    "        training_loss: float,\n",
    "        validation_loss: float,\n",
    "        example_ct: int,\n",
    "        epoch: int,\n",
    "        learning_rate: float) -> None:\n",
    "    \"\"\"Logs loss to the console and wandb.\"\"\"\n",
    "    # Where the magic happens\n",
    "    wandb.log(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'learning_rate': learning_rate,\n",
    "            'training_loss': training_loss,\n",
    "            'validation_loss': validation_loss,\n",
    "        },\n",
    "        step=example_ct,\n",
    "    )\n",
    "    logging.info(\n",
    "        f\"Training/Validation Loss after {str(example_ct).zfill(5)} examples: \"\n",
    "        f\"{training_loss:.3f} | {validation_loss:.3f}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_average_loss(\n",
    "        data_loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        loss_func: callable) -> float:\n",
    "    \"\"\"Calculates the average loss over a dataset.\"\"\"\n",
    "    running_loss = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)  # noqa: PLW2901\n",
    "            loss = loss_func(model(x), y)\n",
    "            # weighted average of the loss adjusted for the batch size\n",
    "            running_loss += loss.item() * x.shape[0]\n",
    "            total_samples += x.shape[0]\n",
    "    return running_loss / total_samples\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "        criterion: callable,\n",
    "        optimizer_creator: callable,\n",
    "        learning_rates: list[float],\n",
    "        config: dict) -> None:\n",
    "    \"\"\"\n",
    "    Trains the model for the number of epochs specified in the config. Uses early stopping to\n",
    "    prevent overfitting. Takes multiple learning rates and if early stopping is triggered, the\n",
    "    learning rate is reduced and training is continued until no learning rates remain.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    example_ct = 0  # number of examples seen\n",
    "\n",
    "    log_interval = 30 # i.e. every 30 batches\n",
    "    total_batches = len(train_loader)\n",
    "    log_interval = max(1, math.floor(total_batches / log_interval))\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        model=model,\n",
    "        patience=3,\n",
    "        delta=0.05,  # new loss is required to be >%5 better than previous best\n",
    "        delta_type='relative',\n",
    "        verbose=True,\n",
    "    )\n",
    "    learning_rate = learning_rates.pop(0)\n",
    "    optimizer = optimizer_creator(lr=learning_rate)\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        logging.info(f\"Epoch {epoch} - learning rate: {learning_rate}\")\n",
    "        running_training_loss = 0\n",
    "        total_train_samples = 0\n",
    "        for batch_index, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)  # noqa: PLW2901\n",
    "            # ➡ Forward pass\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            # ⬅ Backward pass & optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(x_batch)\n",
    "            # weighted average of the training loss\n",
    "            running_training_loss += loss.item() * x_batch.shape[0]\n",
    "            total_train_samples += x_batch.shape[0]\n",
    "            # Report metrics every 25th batch\n",
    "            if batch_index % log_interval == 0:\n",
    "                avg_training_loss = running_training_loss / total_train_samples\n",
    "                running_training_loss = 0\n",
    "                total_train_samples = 0\n",
    "                model.eval()\n",
    "                average_validation_loss = calculate_average_loss(\n",
    "                    data_loader=validation_loader, model=model, loss_func=criterion,\n",
    "                )\n",
    "                train_log(\n",
    "                    avg_training_loss,\n",
    "                    average_validation_loss,\n",
    "                    example_ct,\n",
    "                    epoch,\n",
    "                    learning_rate,\n",
    "                )\n",
    "                model.train()\n",
    "\n",
    "        if early_stopping(average_validation_loss):\n",
    "            logging.info(\"Early stopping. Loading previous best state.\")\n",
    "            # we have stopped training (for this learning rate), load the previous best state\n",
    "            model.load_state_dict(early_stopping.best_state)\n",
    "            # if we have more learning rates, reset the optimizer and early stopping and\n",
    "            # continue training\n",
    "            if learning_rates:\n",
    "                learning_rate = learning_rates.pop(0)\n",
    "                logging.info(f\"Reducing learning rate: {learning_rate}\")\n",
    "                optimizer = optimizer_creator(lr=learning_rate)\n",
    "                early_stopping.reset()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    wandb.log({\n",
    "        'best_validation_loss': early_stopping.lowest_loss,\n",
    "        'best_index': early_stopping.best_index,\n",
    "    })\n",
    "    logging.info(f\"Best validation loss: {early_stopping.lowest_loss:.3f}; index {early_stopping.best_index}\")  # noqa: E501\n",
    "\n",
    "\n",
    "def plot_misclassified_sample(\n",
    "        num_images: int,\n",
    "        images: torch.tensor,\n",
    "        predictions: np.array,\n",
    "        labels: np.array) -> None:\n",
    "    \"\"\"Plot a sample of the misclassified images.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=num_images // 5, ncols=5, sharex=True, sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    mismatched_indexes = np.where(predictions != labels)[0]\n",
    "    rows = np.random.choice(mismatched_indexes, size=num_images, replace=False)  # noqa: NPY002\n",
    "    for i, row in enumerate(rows):\n",
    "        # img = X_test[row].cpu().numpy().reshape(28, 28)\n",
    "        img = images[row].cpu().numpy().reshape(28, 28)\n",
    "        ax[i].imshow(img, cmap='Greys')\n",
    "        title_color = 'red' if predictions[row] != y_test[row] else 'black'\n",
    "        ax[i].set_title(f'P:{predictions[row]} - A:{y_test[row]}', color=title_color)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    wandb.log({'sample-misclassified': wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def plot_heatmap(predictions: np.array, labels: np.array) -> None:\n",
    "    \"\"\"Plot a heatmap of the misclassified samples.\"\"\"\n",
    "    # create a heatmap of misclassified samples\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    # remove the diagonal values (correct predictions) for better visualization\n",
    "    np.fill_diagonal(cm, 0)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Count of Misclassified Samples by Class')\n",
    "    wandb.log({'count-misclassified': wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def plot_scores(precision: list, recall: list, f1: list) -> None:\n",
    "    \"\"\"Plot the precision, recall, and f1 scores for each class.\"\"\"\n",
    "    # create a bar plot\n",
    "    x = range(10)\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.bar(x, precision, width, label='Precision')\n",
    "    _= ax.bar([i + width for i in x], recall, width, label='Recall')\n",
    "    _ = ax.bar([i + 2 * width for i in x], f1, width, label='F1')\n",
    "    # add labels, title, and legend\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Accuracy Metrics by Class')\n",
    "    ax.set_xticks([i + width for i in x])\n",
    "    ax.set_xticklabels(range(10))\n",
    "    ax.legend()\n",
    "    # find the minimum and maximum score values (from precision, recall, and f1 lists) and set the\n",
    "    # y limits slightly wider to make the plot easier to read\n",
    "    ymin = min(*precision, *recall, *f1)\n",
    "    ymax = max(*precision, *recall, *f1)\n",
    "    ax.set_ylim([ymin - 0.03, min(ymax + 0.03, 1)])\n",
    "    wandb.log({'scores': wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def test(model: nn.Module, test_loader: DataLoader, criterion: callable) -> None:\n",
    "    \"\"\"Tests the model on the test set. Logs the accuracy to the console and to wandb.\"\"\"\n",
    "    model.eval()\n",
    "    avg_test_loss = calculate_average_loss(data_loader=test_loader, model=model, loss_func=criterion)  # noqa\n",
    "    logging.info(f\"Average Loss on test set: {avg_test_loss:.3f}\")\n",
    "    wandb.log({'test_loss': avg_test_loss})\n",
    "\n",
    "    # Log confusion matrix\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(DEVICE), y.cpu().numpy()  # noqa: PLW2901\n",
    "            outputs = model(x)\n",
    "            predictions = torch.argmax(outputs.data, dim=1).cpu().numpy()\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(y)\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    plot_misclassified_sample(num_images=30, images=x_test, predictions=all_predictions, labels=all_labels)  # noqa\n",
    "    plot_heatmap(predictions=all_predictions, labels=all_labels)\n",
    "\n",
    "    # for each class, calculate the accuracy metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true=all_labels, y_pred=all_predictions)  # noqa\n",
    "    score_table = wandb.Table(columns=[\"class\", \"precision\", \"recall\", \"f1\"])\n",
    "    for i in range(10):\n",
    "        score_table.add_data(str(i), precision[i], recall[i], f1[i])\n",
    "    wandb.log({\"score_table\": score_table})\n",
    "    plot_scores(precision, recall, f1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true=all_labels,\n",
    "        y_pred=all_predictions,\n",
    "        average='weighted',\n",
    "    )\n",
    "    logging.info(f\"Weighted Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "    wandb.log({'weighted_precision': precision, 'weighted_recall': recall, 'weighted_f1': f1})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    x, _ = next(iter(test_loader))\n",
    "    torch.onnx.export(model, x.to(DEVICE) , 'model.onnx')\n",
    "    wandb.save('model.onnx')\n",
    "\n",
    "\n",
    "def model_pipeline(config: dict) -> nn.Module:\n",
    "    \"\"\"Builds the model and runs it.\"\"\"\n",
    "    # tell wandb to get started\n",
    "    project = config.pop('project'); assert project\n",
    "    tags = config.pop('tags', None)\n",
    "    notes = config.pop('notes', None)\n",
    "    with wandb.init(project=project, config=config, tags=tags, notes=notes):\n",
    "        config = wandb.config\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, validation_loader, test_loader, criterion, optimizer_creator, \\\n",
    "            learning_rates = make(config)\n",
    "        print(model)\n",
    "        # and use them to train the model\n",
    "        train(\n",
    "            model, train_loader, validation_loader, criterion, optimizer_creator,\n",
    "            learning_rates, config,\n",
    "        )\n",
    "        # and test its final performance\n",
    "        test(model, test_loader, criterion)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/code/source/notebooks/wandb/run-20231229_200401-4yzlstn4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shane-kercheval/pytorch-demo/runs/4yzlstn4' target=\"_blank\">peachy-energy-29</a></strong> to <a href='https://wandb.ai/shane-kercheval/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shane-kercheval/pytorch-demo' target=\"_blank\">https://wandb.ai/shane-kercheval/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shane-kercheval/pytorch-demo/runs/4yzlstn4' target=\"_blank\">https://wandb.ai/shane-kercheval/pytorch-demo/runs/4yzlstn4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    'project': 'pytorch-demo',\n",
    "    'tags': ['pytorch', 'demo'],\n",
    "    'notes': 'First run with a simple CNN',\n",
    "    'epochs': 20,\n",
    "    'classes': 10,\n",
    "    'kernels': [16, 32],\n",
    "    'batch_size': 64,\n",
    "    'optimizer': 'Adam',\n",
    "    # 'learning_rates': 0.005,\n",
    "    'learning_rates': [0.005, 0.001, 0.0005],\n",
    "    'dataset': 'MNIST',\n",
    "    'architecture': 'CNN',\n",
    "}\n",
    "# Build, train and analyze the model with the pipeline\n",
    "model = model_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
